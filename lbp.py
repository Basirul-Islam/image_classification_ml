# -*- coding: utf-8 -*-
"""lbp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DFx4JvA5yyLVspWdOZ8Q705mHgFCYZju
"""

#from google.colab import drive
#drive.mount('/content/drive')

import os
import joblib
import seaborn
from skimage.io import imread
from skimage.filters import gaussian
from skimage.transform import resize
import numpy as np

from sklearn.decomposition import PCA
from skimage.feature import local_binary_pattern
from sklearn.model_selection import train_test_split
from scipy.spatial import distance
import matplotlib.pyplot as plt
import pandas as pd

def read_data(datadir, categories, height, width):
    # labels, data = [], []
    # class_counter = 0
    # categories=['Bacterial leaf blight','Brown spot','Leaf smut']

    flat_data_arr=[] #input array
    target_arr=[] #output array
    # datadir= '/content/drive/MyDrive/animal/train'#'/content/drive/MyDrive/input/rice_leaf_diseases'

    # class_directories = os.listdir(path)
    for category in categories:
      count = 0
      print(f'Readingding... category : {category}')
      path=os.path.join(datadir,category)
      for img in os.listdir(path):
          count = count + 1
          #if(count>20): break
          if(count>30 and datadir != 'TestData'):
              break
          elif(count>100): break
          img_array = imread(os.path.join(path,img), True)
          img_array = gaussian(img_array, sigma=0.4)
          img_resized = resize(img_array,(height, width), mode='constant', preserve_range=True)
          
          flat_data_arr.append(img_resized)
          target_arr.append(categories.index(category))
      print(f'Readded category: {category} successfully')
    
    return flat_data_arr, target_arr



def get_hist_from_lbph(data):
    # reference:
    # pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/
    eps = 1e-7
    radius = 2
    n_points = 8 * radius
    lbp = local_binary_pattern(data, n_points, radius, 'uniform')
    (hist, _) = np.histogram(lbp.ravel(), bins = np.arange(0, n_points + 3), range = (0, n_points + 2))
    hist = np.array(hist, dtype = np.float32)
    
    return hist



def get_histogram_feature(X_train, X_test):
    features, test_features = [], []

    for X_train_sample in X_train:
        features.append(get_hist_from_lbph(X_train_sample))
    for X_test_sample in X_test:
        test_features.append(get_hist_from_lbph(X_test_sample))
  
    return features, test_features
def get_lbp_prediction():
    seed = 77
    height, width = 300, 400
    categories = ['Boot','Shoe','Sandal'] #'Bacterial leaf blight','Brown spot','Leaf smut'
    # read data
    data, labels = read_data('DataSet/', categories, height, width)

    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.10, random_state=seed)

    X_train_feature, X_test_feature = get_histogram_feature(X_train, X_test)
    # experiment with lbp
    # lbp_preds, lbp_gt = experiment_with_lbp(X_train, X_test, y_train, y_test)

    # from sklearn.metrics import accuracy_score
    # print(accuracy_score(lbp_gt, lbp_preds))

    from sklearn import svm
    from sklearn.model_selection import GridSearchCV

    param_grid = {'C':[0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf','poly']}
    svc = svm.SVC(probability = True)
    model = GridSearchCV(svc, param_grid)

    model.fit(X_train_feature, y_train)
    #joblib.dump(model, 'saved_models/lbp.pkl')
    print('The Model is trained well with the given images and saved')

    from sklearn.metrics import classification_report,accuracy_score
    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

    y_pred = model.predict(X_test_feature)
    # y_true = y_pred
    cm = confusion_matrix(y_test, y_pred)
    '''import matplotlib
    matplotlib.use('TkAgg')
    names = ['Boot', 'Shoe', 'Sandal']
    confusion_df = pd.DataFrame(cm, index=names, columns=names)
    plt.figure(figsize=(5, 5))
    seaborn.heatmap(confusion_df, annot=True, annot_kws={"size": 12}, cmap='YlGnBu', cbar=False, square=True, fmt='.2f')
    plt.ylabel(r'True Value', fontsize=14)
    plt.xlabel(r'Predicted Value', fontsize=14)
    plt.tick_params(labelsize=12)
    plt.show()'''
    #disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = categories)
    #disp.plot()

    y_pred = model.predict(X_test_feature)
    print("The predicted Data is :")
    print(y_pred)
    print("The actual data is:")
    print(np.array(y_test))
    print(f"The model is {accuracy_score(y_pred, y_test)*100}% accurate")

    test_data, test_labels = read_data('TestData', categories, height, width)

    features =  []

    for sample in test_data:
        features.append(get_hist_from_lbph(sample))
    y_pred = model.predict(features)

    cm = confusion_matrix(test_labels, y_pred)

    print("The predicted Data is :")
    print(y_pred)
    print("The actual data is:")
    print(np.array(test_labels))
    print(f"The model is {accuracy_score(y_pred, test_labels)*100}% accurate")


    import matplotlib
    matplotlib.use('TkAgg')

    names = ['Boot','Shoe','Sandal']
    confusion_df = pd.DataFrame(cm, index=names, columns=names)
    plt.figure(figsize=(5, 5))
    plt.title('LBP')
    seaborn.heatmap(confusion_df, annot=True, annot_kws={"size": 12}, cmap='YlGnBu', cbar=False, square=True, fmt='.2f')
    plt.ylabel(r'True Value', fontsize=14)
    plt.xlabel(r'Predicted Value', fontsize=14)
    plt.tick_params(labelsize=12)
    plt.show()
